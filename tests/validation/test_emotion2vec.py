import torch
import torchaudio
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC
import numpy as np
from test_llama2_story import get_memory_usage

def test_emotion2vec():
    print("=" * 60)
    print("ğŸ˜Š TESTE: Emotion2Vec - Audio Emotion Analysis")
    print("=" * 60)
    
        # Usando modelo prÃ©-treinado para portuguÃªs
    model_name = "jonatasgrosman/wav2vec2-large-xlsr-53-portuguese"
    
    ram_before, vram_before = get_memory_usage()
    print(f"\nğŸ“Š MemÃ³ria Antes: RAM {ram_before:.2f}GB | VRAM {vram_before:.2f}GB")
    
    print("\nâ³ Carregando Emotion2Vec...")
    processor = Wav2Vec2Processor.from_pretrained(model_name, do_lower_case=True)
    print("\nâ³ Carregando modelo de portuguÃªs...")
    # Para reconhecimento de fala, nÃ£o de emoÃ§Ã£o
    model = Wav2Vec2ForCTC.from_pretrained(model_name).to("cuda")
    
    ram_after, vram_after = get_memory_usage()
    print(f"âœ… Carregado")
    print(f"ğŸ“Š MemÃ³ria: RAM {ram_after:.2f}GB | VRAM {vram_after:.2f}GB")
    
    # Ãudio de teste
    sample_rate = 16000
    audio = torch.randn(1, sample_rate * 5).numpy()  # 5s de Ã¡udio
    
    # Reconhecimento de fala (transcriÃ§Ã£o)
    print("\nğŸ—£ï¸ Transcrevendo Ã¡udio...")
    inputs = processor(audio[0], sampling_rate=sample_rate, return_tensors="pt", padding=True)
    inputs = {k: v.to("cuda") for k, v in inputs.items()}
    with torch.no_grad():
        logits = model(**inputs).logits
    predicted_ids = torch.argmax(logits, dim=-1)
    transcription = processor.batch_decode(predicted_ids)[0]
    print(f"ï¿½ TranscriÃ§Ã£o: {transcription}")
    print("\nâœ… TESTE CONCLUÃDO")
    print("\nâš ï¸  Para anÃ¡lise de emoÃ§Ã£o, Ã© necessÃ¡rio realizar fine-tuning supervisionado com dataset de emoÃ§Ãµes em portuguÃªs.")
    # Reconhecimento de fala (transcriÃ§Ã£o)
    print("\nğŸ—£ï¸ Transcrevendo Ã¡udio...")
    inputs = processor(audio[0], sampling_rate=sample_rate, return_tensors="pt", padding=True)
    inputs = {k: v.to("cuda") for k, v in inputs.items()}
    
    with torch.no_grad():
        logits = model(**inputs).logits
        predicted_ids = torch.argmax(logits, dim=-1)
        transcription = processor.batch_decode(predicted_ids)[0]
    
        print(f"ğŸ“ TranscriÃ§Ã£o: {transcription}")
        print("\nâœ… TESTE CONCLUÃDO")
        print("\nâš ï¸  Para anÃ¡lise de emoÃ§Ã£o, Ã© necessÃ¡rio realizar fine-tuning supervisionado com dataset de emoÃ§Ãµes em portuguÃªs.")
    return True

if __name__ == "__main__":
    test_emotion2vec()